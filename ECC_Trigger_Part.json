{"name":"ECC_Trigger_Part","appVersion":"-SNAPSHOT","description":"Data Pipeline Application","change":{"author":"cdap","creationTimeMillis":1681739199899,"latest":true},"configuration":"{\"resources\":{\"memoryMB\":2048.0,\"virtualCores\":1.0},\"driverResources\":{\"memoryMB\":2048.0,\"virtualCores\":1.0},\"connections\":[],\"comments\":[],\"postActions\":[],\"properties\":{},\"processTimingEnabled\":true,\"stageLoggingEnabled\":false,\"stages\":[{\"name\":\"Verify inputs\",\"plugin\":{\"name\":\"PySparkProgram\",\"type\":\"sparkprogram\",\"label\":\"Verify inputs\",\"artifact\":{\"name\":\"dynamic-spark\",\"version\":\"2.2.3\",\"scope\":\"USER\"},\"properties\":{\"pythonCode\":\"from pyspark import *\\nfrom pyspark.sql import *\\nfrom cdap.pyspark import SparkExecutionContext\\nimport google.auth\\nfrom google.cloud import storage\\nimport traceback\\nimport re\\nimport logging\\n\\nsec \\u003d SparkExecutionContext()\\nsc \\u003d SparkContext()\\n\\n# reading the required properties from runtime arguments\\nproject_id \\u003d \\\"${project-id}\\\"\\nextracted_data_bucket_name \\u003d \\\"${extracted-data-bucket}\\\" if \\\"gs://\\\" not in \\\"${extracted-data-bucket}\\\" else \\\"${extracted-data-bucket}\\\".split(\\\"gs://\\\")[1]\\nsource \\u003d \\\"${source}\\\"\\ntimestamp \\u003d \\\"${timestamp}\\\"\\nextracted_data_dir \\u003d source + \\\".\\\" + timestamp\\ntarget_files \\u003d \\\"${extracted-files}\\\"\\n\\nstorage_client \\u003d storage.Client()\\nextracted_data_bucket \\u003d storage_client.get_bucket(extracted_data_bucket_name)\\n  \\ndef find_blob(blob_path):\\n  blob \\u003d extracted_data_bucket.get_blob(blob_path)\\n  return blob\\n\\ndef verify_input(file_path):\\n  print(f\\\"--------------------Verify input file: {file_path}--------------------\\\")\\n  blob \\u003d find_blob(file_path)\\n  blob_exists \\u003d blob.exists()\\n  if blob_exists:\\n    blob_size \\u003d f\\\"{blob.size} bytes\\\"\\n    if blob_size \\u003d\\u003d \\\"0 bytes\\\":\\n      print(f\\\"--------------------Empty File Detected!!!: {blob.name}--------------------\\\")\\n      raise Exception(f\\\"Verify inputs - Failed for File: {file_path} as it is Empty!\\\")\\n  \\ndef verify_all_inputs():\\n  targeted_input_files_list \\u003d target_files.split(\\u0027,\\u0027)\\n  print(f\\\"--------------------List of Targeted Files for \\u0027Verify inputs\\u0027: {target_files}--------------------\\\")\\n  for target_input_file in targeted_input_files_list:\\n    file_path \\u003d extracted_data_dir + \\\"/\\\" + target_input_file\\n    verify_input(file_path)\\n    \\n\\nprint(\\\"\\u003c\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003dPre processing execution STARTED\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003e\\\")\\nverify_all_inputs()\\nprint(\\\"\\u003c\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003dPre processing execution COMPLETED\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003d\\u003e\\\")\"}},\"outputSchema\":\"\",\"id\":\"Verify-inputs\"}],\"schedule\":\"0 1 */1 * *\",\"engine\":\"spark\",\"numOfRecordsPreview\":100.0,\"rangeRecordsPreview\":{\"min\":1.0,\"max\":\"5000\"},\"description\":\"Data Pipeline Application\",\"maxConcurrentRuns\":1.0}","datasets":[],"programs":[{"type":"Spark","app":"ECC_Trigger_Part","name":"phase-1","description":""},{"type":"Workflow","app":"ECC_Trigger_Part","name":"DataPipelineWorkflow","description":"Data Pipeline Workflow"}],"plugins":[{"id":"ca02759c-21e8-4ccc-86b1-37a023d4df86","name":"PySparkProgram","type":"sparkprogram"},{"id":"Verify inputs","name":"PySparkProgram","type":"sparkprogram"}],"artifact":{"name":"cdap-data-pipeline","version":"6.8.0","scope":"SYSTEM"}}